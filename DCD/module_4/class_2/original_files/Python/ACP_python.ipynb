{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Colombia\n",
    "### Diplomado Ciencia de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de componentes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este caso práctico muestra un ejemplo de cómo hacer un análisis de componentes principales en R La meta del caso es conocer una de las funciones más usadas en R para hacer análisis de componentes principales. Entender las salidas que ofrece y tomar decisiones de análisis basadas en ellas.\n",
    "\n",
    "**Contexto:** El sector de los bienes raíces es uno de los más exitosos en la economía del mundo. La gran mayoría de personas en el mundo deciden rentar sus viviendas por comodidad o economía.\n",
    "\n",
    "**Problema de negocio:** Existen relaciones fuertes entre las variables a considerar cuando se busca un inmueble para rentarlo? Si es así cómo podría resumir esta información para lograr encontrar un lugar de renta\n",
    "\n",
    "Empezaremos por cargar las librerías requeridas para este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "Vamos a utilizar una tabla de datos que contiene información sobre los inmuebles en renta y sus características en el mercado de Brasil. La documentación de los mismos puede encontrarse en https://www.kaggle.com/rubenssjr/brasilian-houses-to-rent?select=houses_to_rent_v2.csv Así pues, para cada inmueble se tiene la siguiente información: \n",
    "- city: ciudad donde la propiedad esta ubicada \n",
    "- area: area de la propiedad \n",
    "- rooms: número de cuartos \n",
    "- bathroom: número de baños \n",
    "- parking spaces: número de parqueaderos \n",
    "- floor: piso - animal : acepta animales \n",
    "- furnished: esta amoblada \n",
    "- hoa: administración \n",
    "- rent amount: renta \n",
    "- property tax: impuesto predial \n",
    "- fire insurance: seguro de incendio \n",
    "- total: valor total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('houses_to_rent_v2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento y limpieza\n",
    "Debemos modificar la variable floor ya que sería interesante incluirla como un valor numérico. Sin embargo el tipo de variable es un factor y contiene el valor ‘-’ para referirse al ground floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['floor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['floor']=='-','floor'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos hacer un análisis por componentes principales en datos sobre inmuebles rentados. Para acotar nuestro análisis filtraremos únicamente los registros de Sao Paulo. Adicionalmente, para ésta técnica únicamente requerimos de las variables numéricas, por lo cual excluimos del análisis las variables **animal** y **furnished**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp = data[data['city']=='São Paulo']\n",
    "data_acp = data_acp[['area','rooms','bathroom','parking spaces','floor','hoa','rent','property_tax','fire_insurance','total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración\n",
    "Empecemos haciendo una exploración de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos revisar la correlación entre las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_acp.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior ya podemos entender el funcionamiento de los datos. Aquí podemos tomar la decisión de sacar información que se vuelve redundante. En particular, la variable total resulta ser la suma de hoa, rent,property_tax y fire_insurance. Podemos observar la relación lineal casi perfecta entre el costo total y el seguro contra incendios, probablemente se calcula de acuerdo al canon de arrendamiento. En este punto podemos quedarnos únicamente con las variables hoa y rent las cuales contienen suficiente información para entender los costos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp = data_acp[['area','rooms','bathroom','parking spaces','floor','hoa','rent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de componentes principales es sensible a las dimensiones. Es recomendable siempre hacer una estandarización de las variables a utilizar para que las unidades de análisis no interfieran en el análisis. La idea es llevar todas las variables a la misma escala, así esta no interfiere con los resultados del análisis. Esto lo podemos hacer transformando a las variables para que tengan media cero y varianza 1. Hagamos la estandarización del valor de la renta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la media de la variable\n",
    "media_renta = data_acp['rent'].mean()\n",
    "# Calculamos la desviación estándar\n",
    "ds_renta = data_acp['rent'].std()\n",
    "# a cada valor restamos la media y dividimos por la desviación estándar\n",
    "data_acp['renta_std1'] = (data_acp['rent']-media_renta)/(ds_renta)\n",
    "# Revisemos el resultado\n",
    "data_acp[['rent','renta_std1']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp[['rent','renta_std1']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe también en Python tenemos una función **StandardScaler** que hace éste cómputo por nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto scaler\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos y transformamos los datos\n",
    "data_acp['renta_std2'] = scaler.fit_transform(data_acp[['rent']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp[['rent','renta_std1','renta_std2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp[['rent','renta_std1','renta_std2']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos estas dos columnas creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acp = data_acp[['area','rooms','bathroom','parking spaces','floor','hoa','rent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de componentes principales\n",
    "\n",
    "La gran mayoría de implementaciones en R o Python de ACP tienen la posibilidad de estandarizar las variables dentro de la función. En este caso utilizaremos la función PCA de la librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scale =  scaler.fit_transform(data_acp[['area','rooms','bathroom','parking spaces','floor','hoa','rent']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_renta = pca.fit(data_scale)\n",
    "pca_renta = pca.transform(data_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos describir entonces cómo está hecha la combinación lineal de cada variable original para definir los componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, la primer componente se puede definir así:\n",
    "\n",
    "$CP1=0.26area+0.47rooms+0.50bathroom+0.47parking−0.017floor+0.13hoa+0.44rent$\n",
    "\n",
    "Estos pesos de cada variable en el primer componente nos dan una idea de qué información está recogiendo la dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también revisar cómo está representada cada observación en las nuevas dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = pca_renta, columns = ['PC1', 'PC2','PC3', 'PC4','PC5', 'PC6','PC7'])\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso seguido podemos visualizar los valores propios para saber qué tan buena es la reducción en los componentes principales. Utilizaremos **explained_variance_** para obtener los valores propios o varianza explicada y **explained_variance_ratio_** para saber el porcentaje de varianza explicada por cada componente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(np.array([1,2,3,4,5,6,7]),pca.explained_variance_ratio_)\n",
    "ax.set(xlabel = \"Dimension\",\n",
    "       ylabel = \"Porcentaje de varianza explicada\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos hacer una visualización de las variables originales en las nuevas dimensiones. Primero revisemos las dos primeras componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the PCA components (loadings)\n",
    "PCs = pca.components_\n",
    "\n",
    "# Use quiver to generate the basic plot\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "           PCs[0,:], PCs[1,:], \n",
    "           angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# Add labels based on feature names (here just numbers)\n",
    "feature_names = np.array(['area', 'rooms', 'bathroom', 'parking spaces', 'floor', 'hoa', 'rent'])\n",
    "\n",
    "for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# Add unit circle\n",
    "circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Ensure correct aspect ratio and axis limits\n",
    "plt.axis('equal')\n",
    "plt.xlim([-1.0,1.0])\n",
    "plt.ylim([-1.0,1.0])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cercanía al circulo unitario es un indicativo de qué tan buena es ésta representación para cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the PCA components (loadings)\n",
    "PCs = pca.components_\n",
    "\n",
    "# Use quiver to generate the basic plot\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "           PCs[0,:], PCs[2,:], # primera y tercera dimension\n",
    "           angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# Add labels based on feature names (here just numbers)\n",
    "feature_names = np.array(['area', 'rooms', 'bathroom', 'parking spaces', 'floor', 'hoa', 'rent'])\n",
    "\n",
    "for i,j,z in zip(PCs[2,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# Add unit circle\n",
    "circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Ensure correct aspect ratio and axis limits\n",
    "plt.axis('equal')\n",
    "plt.xlim([-1.0,1.0])\n",
    "plt.ylim([-1.0,1.0])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 3')\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también visualizar los individuos en el mismo plano. Dado que tenemos 5887 observaciones la siguiente función puede tomar mucho tiempo para graficar los resultados. Por esta razón, sólo graficaremos las primeras 150 observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = principalDf.loc[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot('PC1',\n",
    "               'PC2',\n",
    "               data=df,\n",
    "               fit_reg=False,\n",
    "               scatter=True)\n",
    "               #size=7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Qué conclusiones podríamos sacar del biplot de la primer y segunda componente?**\n",
    "\n",
    "\n",
    "**2. Ajustemos el mismo análisis para la ciudad de Rio de Janeiro, ¿qué resultados se obtienen? ¿hay diferencias con el análisis anterior?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El análisis de componentes principales resulta ser una gran herramienta para resumir información \n",
    "\n",
    "- Se pueden visualizar y encontrar patrones de forma multivariada\n",
    "\n",
    "- Es posible identificar también información recurrente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
