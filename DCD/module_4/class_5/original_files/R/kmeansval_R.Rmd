---
title: "Universidad Nacional de Colombia"
subtitle: "Diplomado Ciencia de datos"
output: html_document
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#knitr::knit_hooks$set(webgl = hook_webgl)
# cargue librerias 
library(ggplot2)
library(ggpubr)
library(ggcorrplot)
library(dplyr)
library(factoextra)
library(knitr)
library(rgl)
library(cluster)
knit_hooks$set(rgl = hook_rgl)
```

## Validaci贸n k-means

En este caso pr谩ctico continuaremos con el caso de clustering que hicimos la clase anterior. Haremos la validaci贸n de nuestra aplicaci贸n de k-means.

El caso estar谩 estructurado as铆

1. Resumir el caso anterior
2. Ajustar y comparar distintos k-means
3. Revisar criterios de validaci贸n
4. Hacer conclusiones a partir del an谩lisis


**Contexto:**  Las competencias deportivas cada d铆a recogen una gran cantidad de datos relacionados con el desempe帽o de sus equipos y jugadores para encontrar patrones en estos datos y tomar decisiones informadas basadas en ellos. De esta manera la competencia aumenta tanto dentro como fuera de la cancha.


**Problema de negocio:**  Se tienen los datos de desempe帽o de los equipos de baloncesto del torneo NCAA March Madness que contiene las estad铆sticas de juego de 353 equipos de la liga. El objetivo es inspeccionar esta data utilizando t茅cnicas de visualizaci贸n y agrupaci贸n para encontrar patrones en el desempe帽o de los equipos y generar recomendaciones de umbrales en las estad铆sticas para que un equipo est茅 en el grupo de desempe帽o superior.


```{r}
# ruta directorio
setwd('C:/Users/Juliana/Desktop/Diplomado/D_2020/Casos/Casos/Cluster_validation') 
```




```{r}
## Cargue de datos
datos <- read.csv('basketball_19.csv',header=T)
head(datos)
```

Estas son las variables que contiene el conjunto de datos 

- TEAM: Equipo
- CONF: La conferencia en la que el equipo participa(A10 = Atlantic 10, ACC = Atlantic Coast Conference, AE = America East, Amer = American, ASun = ASUN, B10 = Big Ten, B12 = Big 12, BE = Big East, BSky = Big Sky, BSth = Big South, BW = Big West, CAA = Colonial Athletic Association, CUSA = Conference USA, Horz = Horizon League, Ivy = Ivy League, MAAC = Metro Atlantic Athletic Conference, MAC = Mid-American Conference, MEAC = Mid-Eastern Athletic Conference, MVC = Missouri Valley Conference, MWC = Mountain West, NEC = Northeast Conference, OVC = Ohio Valley Conference, P12 = Pac-12, Pat = Patriot League, SB = Sun Belt, SC = Southern Conference, SEC = South Eastern Conference, Slnd = Southland Conference, Sum = Summit League, SWAC = Southwestern Athletic Conference, WAC = Western Athletic Conference, WCC = West Coast Conference)
- G: N煤mero de partidos jugados
- W: N煤mero de partidos ganados
- ADJOE: Estimaci贸n de eficiencia ofensiva, puntos anotados por cada 100 posesiones
- ADJDE: Estimaci贸n de eficiencia defensiva, puntos permitidos por cada 100 posesiones del equipo contrario
- BARTHAG: Probabilidad de vencer a un equipo
- EFG_O: % tiros efectivos a favor
- EFG_D: % tiros efectivos en contra
- TOR: Porcentaje de rotaci贸n permitida (equipo pierde la posesi贸n del bal贸n contra el equipo contrario antes de que un jugador dispare a la canasta de su equipo)
- TORD: Porcentaje de rotaci贸n hecha al equipo contrario (se roba la pelota al contrincante)
- ORB: Porcentaje de rebote ofensivo
- B: Porcentaje de rebote defensivo
- FTR : Tasa de tiros libres hechos(que hace el equipo)
- FTRD: Tasa de tiros libres permitidos (que hace el contrincante)
- 2P_O: Porcentaje de tiros de 2 puntos hechos
- 2P_D: Porcentaje de tiros de 2 puntos permitidos
- 3P_O: Porcentaje de tiros de 3 puntos hechos
- 3P_D: Porcentaje de tiros de 3 puntos permitidos
- ADJ_T: Posesi贸n del bal贸n por 40 min
- WAB: Triunfos por encima de la 'burbuja' (la burbuja es el l铆mite definido para pasar al campeonato NCAA March Madness Tournament
- POSTSEASON: Ronda en la que el equipo de fue eliminado (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)
- SEED: Semilla definida por el torneo


## Exploraci贸n de los datos 


En el caso pasado hicimos una exploraci贸n general de las variables

```{r}
## visualizaci贸n de algunas variables
p1 <- ggplot(datos, aes(x=G)) + geom_histogram(color="blue", fill="blue")
p2 <- ggplot(datos, aes(x=W)) + geom_histogram(color="blue", fill="blue")
p3 <- ggplot(datos, aes(x=ADJOE)) + geom_histogram(color="blue", fill="blue")
p4 <- ggplot(datos, aes(x=ADJDE)) + geom_histogram(color="blue", fill="blue")
p5 <- ggplot(datos, aes(x=BARTHAG)) + geom_histogram(color="blue", fill="blue")


ggarrange(p1, p2, p3,p4, p5,ncol = 2, nrow = 3)

```


Con 茅sta exploraci贸n inicial seleccionamos algunas variables para hacer el an谩lisis de clusters

```{r}
# selecci贸n variables num茅ricas
km_data <- subset(datos, select = -c(TEAM,CONF,POSTSEASON,SEED) )
# selecci贸n variables de inter茅s
km <- km_data[,c('W','ADJOE','BARTHAG','EFG_O','X2P_O','WAB')]
head(km)
```


## Agrupamiento

Al igual que en ACP es importante estandarizar las variables que vamos a utilizar. La funci贸n scale nos permite hacerlo en una sola linea

```{r}
# estandarizar variables 
km_scale <-scale(km)
```


En el caso anterior definimos el n煤mero de clusters como  =3  para el algortimo de kmeans. Al ajustar el agrupamiento jer谩rquico observabamos que otros posibles n煤meros de cluster podr铆amos utilizar

```{r}
# matriz de distancias
mat_dist <- dist(km_scale, method='euclidean') # la funci贸n hclust necesita como insumo una matriz de distancias
# dendograma
dend <- hclust(mat_dist,method='ward.D')
plot(dend)
```

Podemos entonces ajustar el kmeans con  =3 . Adicionalmente, tiene mucha l贸gica ajustarlo con  =4  o  =5

```{r}
### kmeans con 3, 4 y 5 clusters
set.seed(42)
kmeans_3k <- kmeans(km_scale, centers = 3) #k=3

kmeans_4k <- kmeans(km_scale, centers = 4) # k=4

kmeans_5k <- kmeans(km_scale, centers = 5) # k=5
```

## Validaci贸n

Emplearemos validaci贸n interna para comparar las soluciones anteriores. Para esto podemos evaluar la cohesi贸n de los clusters revisando la suma de cuadrados dentro (tot.withinss) y la separaci贸n revisando la suma de cuadrados entre (betweenss)

```{r}
# comparaci贸n suma de cuadrados dentro
# inercia o suma de cuadrados dentro total --> cohesion
kmeans_3k$tot.withinss
kmeans_4k$tot.withinss

```



```{r}
# suma de cuadrados entre clusters -->separaci贸n
kmeans_3k$betweenss
kmeans_4k$betweenss

```

Recordemos que entre menor sea la suma de cuadrados dentro ser谩 mejor la soluci贸n. Sin embargo siempre que se generen m谩s clusters este n煤mero tiende a disminuir. Por esta raz贸n debemos enocontrar un punto de balance entre tener un n煤mero bajo de SSW y un n煤mero adecuado de clusters

Podemos tambi茅n revisar los coeficientes de silhouette para ver qu茅 tan bien asignado est谩 cada punto a su cluster

```{r}
# Silhouette
sil3 <- silhouette(kmeans_3k$cluster,dist(km_scale))
plot(sil3, main ="Silhouette plot - K-means 3 clusters")

sil4 <- silhouette(kmeans_4k$cluster,dist(km_scale))
plot(sil4, main ="Silhouette plot - K-means 4 clusters")
```

Hay menor n煤mero de puntos "mal representados" en la soluci贸n de 3 clusters

## Elecci贸n de k

Utilizaremos la comparaci贸n de valores de suma de cuadrados dentro total con respecto a diferentes valores de   . Este m茅todo es conocido como el m茅todo del codo. Para esto utilizaremos la funci贸n **fviz_nbclust** del paquete **factoextra** que nos permite hacer el gr谩fico directo del m茅todo.

```{r}
# elecci贸n de k 
set.seed(123)
# m茅todo del codo
fviz_nbclust(km_scale, kmeans, method = "wss")
```


## 驴Cu谩l consideran ser铆a el valor 贸ptimo para k seg煤n el m茅todo del codo?

Adicionalmente, podemos revisar el coeficiente de Silhouette

```{r}
# m茅todo de silhouette
fviz_nbclust(km_scale, kmeans, method = "silhouette")
```


## 驴Cu谩l consideran ser铆a el valor 贸ptimo para k seg煤n el m茅todo del silhouette?

No necesariamente los m茅todos deben coincidir ni dan una 煤nica respuesta. Depende del investigador y el contexto analizar qu茅 soluci贸n podr铆a ser mejor


## Validacion estructura clusters


Podemos guardar los clusters asignados por el algoritmo cuando se usaron  =3  y  =4  y evaluar las diferencias entre ellos en c贸mo est谩n definidos en la data

```{r}
# etiquetas de clusters
datos$cluster_3k <- kmeans_3k$cluster
datos$cluster_4k <- kmeans_4k$cluster
```

Revisemos la distribuci贸n de estos clusters

```{r}
# distribuci贸n
table(datos$cluster_3k)
barplot(table(datos$cluster_3k),main='Soluci贸n de 3 clusters')
```


```{r}
table(datos$cluster_4k)
barplot(table(datos$cluster_4k),main='Soluci贸n de 4 clusters')
```

Para tener mayor informaci贸n podr铆amos visualizar las variables originales de acuerdo a los clusters para entender mejor la estructura

**Soluci贸n 3 clusters**

```{r}
# relaci贸n con variables
p1 <- ggplot(datos, aes(x=ADJOE, y=BARTHAG)) + geom_point(aes(color = factor(cluster_3k))) +labs(x = "Efic. Ofensiva",y='Prob ganar')
p2 <- ggplot(datos, aes(x=EFG_O, y=BARTHAG)) + geom_point(aes(color = factor(cluster_3k))) +labs(x = "% Tiros efectivos",y='Prob ganar')
ggarrange(p1, p2,ncol = 2, nrow = 1)
```


```{r,rgl=TRUE}
# 3d plot
plot3d(datos$ADJOE,datos$BARTHAG,datos$EFG_O,col=datos$cluster_3k,
       xlab='Eficiencia Ofensiva',ylab='Probabilidad de ganar',zlab='Tiros efectivos')
```



**Soluci贸n 4 clusters**

```{r}
p1 <- ggplot(datos, aes(x=ADJOE, y=BARTHAG)) + geom_point(aes(color = factor(cluster_4k))) +labs(x = "Efic. Ofensiva",y='Prob ganar')
p2 <- ggplot(datos, aes(x=EFG_O, y=BARTHAG)) + geom_point(aes(color = factor(cluster_4k))) +labs(x = "% Tiros efectivos",y='Prob ganar')
ggarrange(p1, p2,ncol = 2, nrow = 1)
```


```{r,rgl=TRUE}
# 3d plot
plot3d(datos$ADJOE,datos$BARTHAG,datos$EFG_O,col=datos$cluster_4k,
       xlab='Eficiencia Ofensiva',ylab='Probabilidad de ganar',zlab='Tiros efectivos')
```


```{r}
# comparaci贸n correspondencia clusters
table(datos$cluster_3k,datos$cluster_4k)
```


En los anteriores gr谩ficos se observa c贸mo claramente al aumentar el n煤mero de clusters, el nuevo grupo se traslapa con los anteriores. Esta situaci贸n podr铆a llevar a una soluci贸n redundante donde dos clusters van a tener caracter铆sticas muy similares o cercanas. Revisemos la caracterizaci贸n de los clusters con las variables num茅ricas


```{r}
#
datos %>%
  group_by(cluster_3k) %>% 
  summarise_at(vars('W','ADJOE','BARTHAG','EFG_O','X2P_O','WAB'), mean)


# total
datos %>%
  summarise_at(vars('W','ADJOE','BARTHAG','EFG_O','X2P_O','WAB'), mean)  


datos %>%
  group_by(cluster_4k) %>% 
  summarise_at(vars('W','ADJOE','BARTHAG','EFG_O','X2P_O','WAB'), mean)
```


En la soluci贸n de 4 clusters se puede ver como el cluster de nivel medio en la soluci贸n original es ahora reemplazado por dos clusters que podr铆amos considerar de desempe帽o medio-bajo (3) y medio-alto (1)


## Combinaci贸n ACP y Kmeans

Ajustamos un ACP con las variables de inter茅s

```{r}
## Ajustamos el pca, utilizamos la opcion scale=TRUE
pca <- prcomp(km,scale=TRUE)
summary(pca)

```

Revisemos cu谩ntos componentes deber铆amos utilizar

```{r}
# revisamos los valores propios 
fviz_eig(pca)
```


La soluci贸n de 3 componentes guarda suficiente informaci贸n. Guardemos las coordenadas de los componentes en el data frame

```{r}
# puntos en las nuevas dimensiones
datos$CP1 <- pca$x[,1] 
datos$CP2 <- pca$x[,2] 
datos$CP3 <- pca$x[,3] 
```

Evaluemos cu谩ntos clusters deber铆amos tener con estas nuevas variables

```{r}
# m茅todo del codo
fviz_nbclust(datos[,c('CP1','CP2','CP3')], kmeans, method = "wss")
```

Nuevamente, parece que k=4 podr铆a ser un valor apropiado para el n煤mero de clusters

```{r}
# kmeans  
acp_km <- kmeans(datos[,c('CP1','CP2','CP3')], centers = 4) # k=4  
datos$cluster_acp <- acp_km$cluster
```

  
**Comparaci贸n de resultados**

```{r}
## comparacion
acp_km$tot.withinss
kmeans_4k$tot.withinss


# separacion
acp_km$betweenss
kmeans_4k$betweenss

#silhouette
sil_acp <- silhouette(acp_km$cluster,dist(datos[,c('CP1','CP2','CP3')]))
plot(sil_acp, main ="Silhouette plot - K-means 4 clusters a partir de ACP")

sil4 <- silhouette(kmeans_4k$cluster,dist(km_scale))
plot(sil4, main ="Silhouette plot - K-means 4 clusters")

```


```{r}
# tama帽os
table(datos$cluster_acp)
barplot(table(datos$cluster_acp),main='Soluci贸n desde ACP')
table(datos$cluster_4k,datos$cluster_acp)
```


**Validaci贸n de resultados**

```{r}
# relaci贸n con variables
p1 <- ggplot(datos, aes(x=ADJOE, y=BARTHAG)) + geom_point(aes(color = factor(cluster_acp))) +labs(x = "Efic. Ofensiva",y='Prob ganar')
p2 <- ggplot(datos, aes(x=EFG_O, y=BARTHAG)) + geom_point(aes(color = factor(cluster_acp))) +labs(x = "% Tiros efectivos",y='Prob ganar')
ggarrange(p1, p2,ncol = 2, nrow = 1)
```


```{r,rgl=TRUE}
plot3d(datos$ADJOE,datos$BARTHAG,datos$EFG_O,col=datos$cluster_acp,
       xlab='Eficiencia Ofensiva',ylab='Probabilidad de ganar',zlab='Tiros efectivos')
```



## Ejercicios

1. Ajustemos un nuevo kmeans en las variables originales considerando ahora 5 clusters
2. 驴Qu茅 diferencias se evidencian en comparaci贸n con los dos anteriores?
3. Analicemos la carcaterizaci贸n de los 5 clusters con las variables originales, 驴qu茅 nombre le podr铆amos dar a cada uno de los clusters?
4. Despu茅s de analizar estas tres opciones, 驴cu谩l ser铆a la mejor soluci贸n en este caso?


## Conclusiones

- Efectivamente se logran diferenciar tres grandes segmentos en los equipos: desempe帽o bajo, medio y alto
- Las m茅tricas de validaci贸n son una gran herramienta para tomar la decisi贸n sobre el n煤mero de clusters a utilizar
- Tambi茅n es necesario tener en cuenta el contexto de los datos para definir si la soluci贸n tiene sentido
