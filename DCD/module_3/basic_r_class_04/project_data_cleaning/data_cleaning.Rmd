---
title: "Documentation de ciencia de datos"
author: "Guiselle Tatiana Zambrano Penagos"
date: "8/10/2020"
output: html_document
---

# R básico
- **Conferencista:** Felipe Calvo Cepeda
	-	**Emails:**
		- fcalvoc@unal.edu.co
		- fe.calvo@uniandes.edu.co
	-	**GitHub:** [felipe-calvo](https://github.com/felipe-calvo)
- **Monitoras:**
  - Diana Carolina Sanchez Perez
    - **Email:** dicsanchezpe@unal.edu.co
  - Guiselle Tatiana Zambrano Penagos
    - **Email:** gtzambranop@unal.edu.co
- **Fecha de inicio:** 1 de octubre de 2020
- **Fecha de finalización:** 17 de octubre de 2020
- **Material utilizado en esta clase:**
  - [p3-tidy](https://felipe-calvo.github.io/r-101/p3-tidy.html)

Este documento contiene la documentación y resultados de la clase de limpieza de
datos en R, del diplomado de ciencia de datos.

# Limpieza de Datos

## Base de datos Boston Housing

Como hemos discutido con anterioridad, para todos los conjuntos de datos con los que trabajemos es importante tener un contexto en el cual tengamos información sobre cómo fueron recolectados, en qué año(s), qué técnicas de muestreo se usaron para obtener las observaciones y qué personas o entidades fueron los responsables.

- Si los datos los recolectamos nosotros hablamos de **información primaria** y en nuestros reportes/informes debemos hacer explícito el contexto referido.
- Si los datos los obtuvimos de otra fuenta hablamos de **información secundaria** y en los reportes derivados igualmente debemos procurar obtener y referenciar el contexto referido para los datos.

Para la base de datos Boston Housing, podemos consultar el contexto haciendo clic en [este tunel secreto](https://www.kaggle.com/c/boston-housing/overview/description).

**Librerías Utilizadas durante la clase:**

- [tidyverse](https://www.tidyverse.org/):Conjunto de funciones para limpiar,
  procesar, organizar y mostrar datos
- [readxl](https://readxl.tidyverse.org/): leer archivos de excel
- [MICE](https://cran.r-project.org/web/packages/mice/mice.pdf): Imputa los datos a través de un proceso de regresión. Trata de predecir el valor falatante, a través de un modelado. Este también es útil para variables categóricas.
- [naniar](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html): Visualización de datos faltantes
- [MissMech](https://www.rdocumentation.org/packages/MissMech/versions/1.0.2): Permite hacer una prueba de hipótesis.
- [mvnmle](https://www.rdocumentation.org/packages/mvnmle/versions/0.1-11.1): Encuentra la estimación de máxima verosimilitud del vector medio y la matriz de varianza-covarianza para datos normales multivariados con valores perdidos.
- [BaylorEdPsych](https://www.rdocumentation.org/packages/BaylorEdPsych/versions/0.5): Funciones y datos utilizados para los cursos cuantitativos de psicología educativa de la Universidad de Baylor

```{r}
# Cargamos los paquetes
library("tidyverse")
library("readxl")
```

```{r}
# Leemos los datos desde un archivo de Excel
read_xlsx(
  path = "data/Boston_Housing.xlsx", 
  sheet="Data" # Nombre de la hoja de excel
) -> boston_housing_xlsx
str(boston_housing_xlsx)
```

En cualquier escenario, es posible que tengamos datos faltantes. Veámos cómo abordar esta situación.

## Datos faltantes

Existen numerosos procesos de imputación de datos, entre otros:

- **Usando la media de la variable:** Calcular el promedio de los datos que se tienen y se agrega dicho valor en los datos faltantes. Es recomendable usar la **mediana**.
- HotDeck
- ColdDeck
- **[MICE](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/):** Imputa los datos a través de un proceso de regresión. Trata de predecir el valor falatante, a través de un modelado. Este también es útil para variables categóricas.

Vamos a retirar algunos datos de la base de forma aleatoria.

La imputación es la sustitución de valores no informados en una observación por otros. 

**Paper Relacionado:** [Métodos de imputación para el tratamiento de datos faltantes: aplicación mediante R/Splus](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjHo8f0m6bsAhWNiOAKHRCyDnIQFjAAegQIBBAC&url=https%3A%2F%2Fwww.upo.es%2Frevistas%2Findex.php%2FRevMetCuant%2Farticle%2Fdownload%2F2120%2F1689%2F0&usg=AOvVaw0E_Lbd7rntrqiB-mooqMCc)

```{r}
# Instalamos el paquete mice
# install.packages("mice")

# Cargamos mice
library("mice")
```

**Buena práctica:** Evitar modificar la base de datos original

```{r}
# Guardamos la base de datos en otro objeto llamado datos_completo
datos_completos <- boston_housing_xlsx
datos_completos
```

**Amputar datos:** Remover datos.

En el siguiente código se quitan los datos de manera aleatoria.

```{r}
# "amputamos" datos usando el método MCAR: missing completely at random
ampute(datos_completos, prop = 0.5, mech = "MCAR", run = TRUE)$amp -> datos_incompletos
# datos_incompletos
```

Se van a contar la cantidad de valores faltantes (`NA`) por columna.

```{r}
# Mapeamos el número de NAs por cada columna
datos_incompletos %>% map_df(is.na) %>% colSums()
```

Podemos hacer una visualización de los datos perdidos. En la gráfica se ven las variables que tienen la mayor cantidad de datos perdidos.

```{r}
# Instalamos el paquete naniar
# install.packages("naniar")

# Cargamos el paquete naniar
library("naniar")

# Graficamos los datos incompletos
gg_miss_upset(datos_incompletos)
```

Ahora que tenemos datos perdidos en la base de datos, algo que sucede con (mucha) frecuencia, debemos examinar el “comportamiento” de la pérdida de datos, esto es, identificar si existen patrones o situaciones que nos den indicio de por qué se perdieron los datos.

Podemos tener tres patrones de pérdida de datos:

- MCAR (Missing completely at random): Los datos están perdidos de forma aleatoria
- MAR (Missing at random): Perdida aleatoria, pero no todas las columnas tienen datos perdidos.
- NMAR (Not missing at random): Los datos no están perdidos de forma aleatoria.

Idealmente esperamos que si faltan datos se deba al azar. Si encontramos patrones o ciertas regularidades en la pérdida de datos puede ser indicio de un problema en los procesos de captura, almacenamiento o distribución de los datos.

Dicho esto, en R tenemos test para probar si existen dichos patrones irregulares en nuestras bases de datos. En este caso, usaremos el [test de Jamshidian & Jalal (2010)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3124223/).

```{r}
# Instalamos el paquete MissMech 
# install.packages("MissMech")

# Cargamos el paquete MissMech
library("MissMech")
```

Hacemos una prueba de hipótesis para testear si los datos están perdidos de forma aleatoria.

Obtenemos que hay 15 patrones de valores perdidos, uno por cada columna presente en la base de datos.

**Hiótesis:** Datos normales y [homocedásticos](https://economipedia.com/definiciones/homocedasticidad.html), este se comprueba a través del tes de Hawkins

```{r}
# Testeamos si nuestros datos están perdidos de forma MCAR
# Hipótesis nula: no existen diferencias en la forma en que se pierden datos entre las variables
# Dicho de otra manera, los datos están perdidos de forma aleatoria
# Hipótesis alterna: sí existen diferencias (hay patrones de pérdida de datos)
TestMCARNormality(datos_incompletos)
```

Con un p-valor > 0.05 tendríamos evidencia para no rechazar (“aceptar”) la hipótesis nula de que los datos están perdidos de forma aleatoria. Esto es **deseable** si tenemos datos perdidos, y en ese caso, podríamos proceder a imputar los datos faltantes. Si el test hubiese sido significante, sería un indicio de que podemos tener problemas en la captura, almacenamiento o distribución de los datos.

**Advertencia:** este test tiene sentido si por la naturaleza del problema esperamos tener todos los datos completos. Si hay columnas en donde es esperable tener datos faltantes (por ejemplo, por respuestas opcionales) deberíamos correr el test anterior solamente con las columnas (variables) de las que esperamos datos completos.

**Nota:** el test TestMCARNormality del paquete **MissMech** está diseñado para encontrar patrones de pérdida de datos en matrices numéricas. Si tenemos variables categóricas en nuestra base de datos, el test arrojará un error. En ese caso, se podría usar otra estrategia por medio del [test de Little (1998)](https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478722).

```{r}
# Instalamos paquetes 
# install.packages("mvnmle")
# install.packages("BaylorEdPsych")

# A mediados de 2020 estos paquetes fueron desatendidos del CRAN
# Sin embargo, podríamos instalarlos de forma autónoma (standalone)
# [EN] Tools > Install packages > Install from: Package Archive File
# [ES] Herramientas > Instalar paquetes > Instalar desde: Archivo de paquete

# Cargamos paquetes
library("mvnmle")
library("BaylorEdPsych")
```

```{r}
# Hacemos el test de Little
# Hipótesis nula: los datos están perdidos de forma aleatoria
# Asumiendo que siguen una distribución normal multivariada
# Hipótesis alterna: hay patrones de pérdida de datos

# LittleMCAR(datos_con_variables_categoricas) -> little_test
LittleMCAR(datos_incompletos) -> little_test
little_test$p.value
```

Habiendo comprobado que en nuestros datos los valores perdidos se deben al azar, podemos ahora así aplicar métodos de imputación de datos.

### Imputación usando la media

```{r}
# Mapeamos los promedios de los datos 
datos_completos %>% map(mean) -> promedios
promedios
```

```{r}
# Reemplazamos los NAs en cada variable por su respectivo promedio
replace_na(datos_incompletos, promedios) -> datos_imputados_promedios
# datos_imputados_promedios
```

```{r}
# Veamos la diferencia entre los promedios de los datos completos y los imputados
colMeans(datos_completos - datos_imputados_promedios)
```

### Imputación usando MICE

```{r}
# Llamamos el comando mice para imputar los datos
mice(datos_incompletos, printFlag = FALSE) %>% 
  mice::complete() -> datos_imputados_mice
```

```{r}
# Veamos la diferencia entre los promedios de los datos completos y los imputados
colMeans(datos_completos - datos_imputados_mice)
```