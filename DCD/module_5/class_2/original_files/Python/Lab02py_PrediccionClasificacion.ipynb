{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab02 - Predicción y Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el set de datos\n",
    "Vamos a continuar usando el set de datos que limpiamos y transformamos en el [laboratorio pasado](./Lab01py_Preprocesamiento.ipynb) en donde se registran los atributos de varias botellas de vino junto con su calidad.  De esta forma usaremos el mismo dataset a lo largo de todo el flujo del curso como si se tratara de un proyecto real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('data/winequality-white_clean.csv')\n",
    "len(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Predicción  \n",
    "Ya hemos visto los conceptos básicos de una regresión: \n",
    "- Aprendizaje **supervisado**\n",
    "- Predecir una variable **contínua**\n",
    "- Se busca encontrar los **pesos** de las variables para validar cada una de ellas cómo influye en nuestra variable final  \n",
    "\n",
    "Lo primero que debemos hacer es separar nuestra variable objetivo (*score*) de las variables predictivas (En este caso son todas las demás, excepto *high_quality* que será nuestra variable objetivo en el laboratorio de clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_df['score']\n",
    "x = wine_df.drop(['score'], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Población:'+str(len(x)))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "print('Muestra para Entrenamiento:'+str(len(x_train)))\n",
    "print('Muestra para Pruebas:'+str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS (Ordinary Least Squares)\n",
    "\n",
    "Llamado así porque busca los coeficientes de la ecuación que minimizen la suma de las distancias verticales entre los datos y el modelo.  Para aplicar este modelo se debe validar que no haya multicolinealidad entre las variables predictivas, pues no la detecta fácilmente.  \n",
    "![OLS](https://miro.medium.com/max/3268/1*AwC1WRm7jtldUcNMJTWmiA.png)\n",
    "\n",
    "- **Precisión:** Alta, para variables no correlacionadas (Condiciones para OLS [aquí](https://statisticsbyjim.com/regression/ols-linear-regression-assumptions))\n",
    "- **Velocidad:** Rápido\n",
    "- **Explicativo:** Mucho (Peso/Importancia de cada variable)\n",
    "- **Sensible a cambios:** Poco, OLS crea una estimación generalizada a todos los puntos, un solo valor atípico modificará los pesos de las variables pero no drasticamente, pues seguirá convergiendo a los demás puntos\n",
    "- **Deteminístico**: Sí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos con un modelo sencillo: una regresión sobre una sola variable.  Elija una de las columnas predictivas y usémosla como única variable predictiva.  *Ej: chlorides*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ols = smf.ols('score ~ chlorides', data=wine_df)\n",
    "fit_ols = model_ols.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de **una** variable predictiva y una variable objetivo, podemos ver gráficamente el comportamiento de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x['chlorides'], y, c='Purple', label='Datos')\n",
    "y_pred = fit_ols.predict(x['chlorides'])\n",
    "ax.plot(x['chlorides'], y_pred, c='Blue', label='Modelo')\n",
    "plt.xlabel('chlorides')\n",
    "plt.ylabel('score')\n",
    "plt.title('Primer Modelo de Regresión Lineal Simple');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una sola variable es posible que el modelo no se ajuste correctamente a los datos, podemos ver que daría predicciones erradas.  Podemos incluír otras variables al modelo que nos permitan darle más flexibilidad a l ecuación\n",
    "\n",
    "En el parámetro para *smf.ols()* se le indica al modelo que necesitamos una función de la forma:\n",
    "> Y ~ X1 + X2 + X3 + X4 + ... + Xn  \n",
    "\n",
    "En donde Y es nuestra variale objetivo y cada Xi son las variables predictivas para las que se debe buscar un peso en la ecuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ols = smf.ols('score ~ fixed_acidity + volatile_acidity + citric_acid + residual_sugar +\\\n",
    "              chlorides + free_sulfur_dioxide + total_sulfur_dioxide + density + pH+\\\n",
    "              sulphates + alcohol', data=wine_df)\n",
    "fit_ols = model_ols.fit()\n",
    "fit_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion *fit.summary()* nos entrega un montón de información, vamos a analizar las que ma´s nos interesan:  \n",
    "\n",
    "- Modelo utilizado (OLS), cantidad de registros y de variables usadas (incluyendo intercepto)\n",
    "- Df Residuals (Flexibilidad del modelo: #Observacionnes - #Variables) y Df modelo (#Variables -Intercepto) *(Un dato que no da el summary de R)*\n",
    "- R2, en la primera tabla, es el cuadrado del coeficiente de correlación de todas las variables y representa el porcentaje estimado de varianza que puede ser explicado por el modelo.  \n",
    "- Adj. R2 es un R2 que penaliza coeficientes muy grandes o muy bajos y variables redundantes.  \n",
    "- La tabla del centro nos muestra los coeficientes encontrados por el modelo para cada variable, junto con el error estándar de cada uno.  Esto significa que nuestro modelo tiene la forma:\n",
    "\n",
    "$$\n",
    "y = 153.5215 + 0.1088(fixed acidity) - 1.6731(volatile acidity) + ... + 0.2012(alcohol)\n",
    "$$\n",
    "\n",
    "- Los valores t y valores P (*P>t*), para cada variable, indican si esta afecta o no la variable objetivo.  Son valores estadísticos, por lo general se busca que P < 0.05\n",
    "- Intervalo de confianza de cada variable [0.025 - 0.975]\n",
    "\n",
    "Por ahora, vamos a trabajar con estos valores para mejorar nuestro modelo.  Si quieres saber en detalle el significado y el impacto de modificar cada uno de estos resultados, puedes leer más [aquí](https://www.datarobot.com/blog/ordinary-least-squares-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las variables en la función *smf.ols()* para ver si logra aumentar el R2 del modelo.  Por ejemplo:\n",
    "- Revise las variables que, según el  [laboratorio pasado](./Lab01py_Preprocesamiento.ipynb) están correlacionadas entre sí y aquellas que están correlacionadas con la variabe objetivo\n",
    "- Revise las variables que, según el modelo afectan la variable objetivo (*P valores*)  \n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_ols.save('models/model_ols.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Polinomiales  \n",
    "Modelos como el anterior, en los que se define una *\"fórmula\"* para que el modelo encuentre los coeficientes, son muy comunes en las funciones de R.  \n",
    "[scikit-learn](https://scikit-learn.org/dev/index.html), es la librería preferida de los que trabajamos con Machine Learning en **Python**.  No solo para predicción de variables contínuas sino para todo tipo de modelos.  \n",
    ">Por ejemplo, el ejercicio anterior puede realizarse también con esta librería usando la clase *LinearRegression()*  \n",
    "\n",
    "Para ello, es necesario dividir el dataset en entrenamiento y prueba y **diferenciar las variables predictivas (x) de la variable objetivo (y).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "columnas = ['residual_sugar', 'alcohol', 'citric_acid']\n",
    "\n",
    "x_train = x_train[columnas]\n",
    "x_test = x_test[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly = PolynomialFeatures(degree=2)\n",
    "x_train_poly = model_poly.fit_transform(x_train)\n",
    "x_test_poly = model_poly.fit_transform(x_test)\n",
    "\n",
    "model_linpoly = LinearRegression()\n",
    "model_linpoly.fit(x_train_poly, y_train)\n",
    "model_linpoly.feature_names_ = model_poly.get_feature_names()\n",
    "\n",
    "model_linpoly.score(x_test_poly, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En celdas anteriores hemos dividido el conjunto de datos en dos subconjuntos: Entrenamiento y Prueba.  \n",
    "Ahora, hemos tomado solo tres de ellas (*residual_sugar, alcohol, citric_acid*), para el ejemplo y creado y entrenado (*fit*) un modelo polinomial usando únicamente el set de entrenamiento, y hemos calculado el $R2$ (*score*) usando el set de pruebas: **23%**, el modelo aún puede mejorar, esto lo haremos más adelante.  \n",
    "Pero cuál es este modelo/ecuación qué hemos creado, asi como lo vimos en la sección pasada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_linpoly.coef_)\n",
    "print('Cantidad de coeficientes: ' + str(len(model_linpoly.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parecen ser muchos? Porqué? Cómo saber a qué variable corresponde cada uno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' + '.join(['('+str(c)+')*'+f for c,f in \n",
    "          zip(model_linpoly.coef_, model_linpoly.feature_names_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este formato $X0, X1 y X2$ corresponden a nuestras columnas elegidas para el ejemplo: *residual_sugar, alcohol, citric_acid*  \n",
    "\n",
    "Pero no es necesario realizar este calculo cada vez que queramos predecir un dato nuevo. El modelo nos entrega predicciones de un nuevo set de datos usando la función *predict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_linpoly.predict(x_test_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las variables a incluir o no en el modelo, así como el grado de la regresión polinomial para ver si logra aumentar el score del modelo.\n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_poly.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_linpoly, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Clasificación  \n",
    "Ya hemos visto porqué una regresión lineal es diferente a una clasificación, tanto en el concepto como matemáticamente: \n",
    "- Predecir una variable **categórica**\n",
    "- Se busca encontrar los patrones o similitudes entre cada *clase* para poder clasificar después un registro nuevo  \n",
    "\n",
    "Sin embargo, al igual que en la Predicción, lo primero que debemos hacer es separar nuestra variable objetivo (*high_quality*) de las variables predictivas (En este caso son todas las demás, excepto *score* que fue nuestra variable objetivo en el laboratorio de predicción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('data/winequality-red_clean.csv')\n",
    "len(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_df['high_quality']\n",
    "x = wine_df.drop(['high_quality'], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Logística\n",
    "\n",
    "Similar a una regresión lineal, busca definir el comportamiento de los datos a través de una **ecuación**, con la diferencia que en este caso estamos buscando una variable categórica (1/0 o SI/NO), por lo que no nos serviría una ecuación que retorne un valor entre $(-\\infty, \\infty)$.  \n",
    "Sin embago, al ser una ecuación, asume que los datos son linealmente separables:\n",
    "\n",
    "![Logit](https://qph.fs.quoracdn.net/main-qimg-4ddda954955cabf0fb59364cc37232b7.webp)\n",
    "\n",
    "- **Precisión:** Alta, para variables no correlacionadas y modelos linealmente separables\n",
    "- **Velocidad:** Rápido\n",
    "- **Explicativo:** Mucho (Peso/Importancia de cada variable)\n",
    "- **Sensible a cambios:** Mucho, asume que los datos son separables linealmente\n",
    "- **Deteminístico**: No, probabilístico\n",
    "\n",
    "Como el hecho de que sean datos linealmente separables es **muy** importante, vamos a crear un modelo con solo **dos** variables precitivas para poder ver la separación gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "columnas = ['pH', 'alcohol']\n",
    "x_train = x_train[columnas]\n",
    "x_test = x_test[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[columnas[0]], x[columnas[1]], c=y, s=20)\n",
    "plt.xlabel(columnas[0])\n",
    "plt.ylabel(columnas[1])\n",
    "plt.title('high_quality');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, nuestra variable predictiva *high_quality*, representada por el color de los puntos, parece ser linealmente separable por la variable *alcohol*, pero no tanto por la variable *pH*.  \n",
    "\n",
    "Cómo afecta esto al modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(solver='liblinear')\n",
    "model_log.fit(x_train, y_train)\n",
    "print('Error: {}'.format(1 - model_log.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente hemos entrenado el modelo con los datos de entrenamiento y calculamos el error con datos de entrenamiento, aunque no parece un score tan malo, veamos cómo se comporta el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_log.predict(x_test)\n",
    "print('Ground Truth: '+str(np.array(y_test)[:20]))\n",
    "print('Prediciones:  '+str(y_pred[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las variables a incluir en el modelo para ver si logra aumentar el score del modelo y sus predicciones.  Algunas sugerencias:\n",
    "- Valide qué variables permiten la separación lineal de los datos\n",
    "- Puede incluir mas de dos variables para entrenar el modelo, es lo más recomendable, pero recuerde que no será posible visualizar la separación gráficamente\n",
    "- Intente con el parámetro *solver* de la función LogisticRegression(), éste permite generar otro tipo de líneas que pueden mejorar el modelo (Los posibles valores para el parámetro solver son: *'liblinear', 'newton-cg', 'lbfgs', 'sag' y 'saga'*.  Para saber en detalle qué tipo de modelo genera cada uno puede consultar [aqui](https://medium.com/@venali/conventional-guide-to-supervised-learning-with-scikit-learn-logistic-regression-generalized-e9783c414588))\n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_log.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_log, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecinos más cercanos (kNN)\n",
    "\n",
    "Es un método de clasificación para problemas **no lineales**, y tal vez con una metodología/matemática más sencilla.\n",
    "Consiste en ver los datos como puntos en un plano (de N dimensiones cuántas variables incluya el modelo) y clasificar cualquier \"punto nuevo\" en la misma clase a la que pertenescan los *k* puntos más cercanos (*k* puede ser definido por nosotros mismos)\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTIr4A7USCWANPP8HDtHIOmN2HOY_CK1PhL2Q&usqp=CAU\" alt=\"kNN\" width=\"400\"/>\n",
    "\n",
    "- **Precisión:** Depende intensamente del valor de k.  muy eficiente para datasets sin ruido\n",
    "- **Velocidad:** Depende de dimensiones (*Realmente no construye ningún modelo*)\n",
    "- **Explicativo:** Mucho (Es una ecuación sencilla)\n",
    "- **Sensible a cambios:** Mucho a atributos irrelevantes y la complejidad del modelo\n",
    "- **Deteminístico**: Sí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=18)\n",
    "model_knn.fit(x_train, y_train)\n",
    "print('Error: {}'.format(1 - model_knn.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se eligió el número de vecinos (k) aleatoriamente, y con razón no obtuvimos un score bueno. Pero cuidado:\n",
    "- Si k es muy pequeño, tendiendo a 1, el modelo va a decidir por la clase del ejemplo más cercano. Esto hace el modelo muy sensible al ruido o a pequeños cambios.\n",
    "- Si k es muy grande, tendiendo a N, el modelo no podrá gneralizar.  Nunca analizará patrones, reglas, ni similitudes sino que decidirá siempre *lo que diga la mayoría*  \n",
    "\n",
    "**Taller**  \n",
    "Juegue un poco con el valor de k (*n_neighbors* en la función *KNeighborsClassifier*) para mejorar el score del modelo.  \n",
    "También puede intentar eliminando aquellas variables que generen ruido o atípicos sobre los datos.\n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_knn.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_knn, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de Soporte Vectorial (SVM)\n",
    "\n",
    "Cuando hablamos de Regresión logística, buscamos **una línea** que divida los datos de la mejor manera. Pero, qué pasa cuando hay más de una línea que cumple con esta condición? Cómo elegir la mejor?  \n",
    "Las maquinas de soporte vectorial buscan, por el contrario, un *hiperplano*: un conjunto de líneas que maximicen la distancia/margen entre los puntos más cercanos de cada clase.  A estos puntos más cercanos se les conoce como *vectores de soporte*\n",
    "\n",
    "<img src=\"https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2017/08/how-svm-works.png\" alt=\"SVM\" width=\"400\"/>\n",
    "\n",
    "- **Precisión:** Alta si se configura correctamente\n",
    "- **Velocidad:** Lento para una gran cantidad de datos\n",
    "- **Explicativo:** No\n",
    "- **Sensible a cambios:** Si, sobretodo a ejemplos mal etiquetados\n",
    "- **Deteminístico**: Sí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.SVC(probability= True,\n",
    "                    kernel='rbf')\n",
    "model_svm.fit(x_train, y_train)\n",
    "print('Error: {}'.format(1 - model_svm.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aún tenemos un error un poco alto.  Sin embargo, una de las ventajas de SVM, a pesar de ser un algoritmo lento y sensible al ruido, es su versatilidad para manejar problemas no lineales.  Esto lo logra por medio del parámetro **kernell** que permite definir \"la forma\" del/los hiperplano/s que va a generar:\n",
    "![Kernell](https://i.imgur.com/HKTLn35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las columas a incluir en el modelo, así como con el **kernell** de la función *svm.SVC()*.  Los posibles valores de este parámetro son:\n",
    "- 'linear'\n",
    "- 'poly' (Polinomial, en este caso tambien se puede configurar el parámetro *degree*)\n",
    "- 'rbf'\n",
    "- 'sigmoid'\n",
    "\n",
    "Puede que enuentre varios modelos que le parezcan convenientes.  Se sugiere guardar cada uno de la siguiente manera (cambiando el nombre del archivo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_svm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_svm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión\n",
    "\n",
    "Es el tipo de algoritmo más fácil de entender, pues se basa en reglas condicionales muy similares al lenguaje humano (*Si... entonces...*).  El entrenamiento consiste en encontrar las reglas y condiciones que cubran la mayor cantidad de casos.  \n",
    "El modelo gráficamente puede ser representado mediante un árbol en el que los **nodos intermedios** son decisiones basadas en alguno de los atributos predictivos, y las **hojas** son la clase objetivo.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f3/CART_tree_titanic_survivors.png\" alt=\"Decision Tree\" width=\"400\"/>\n",
    "\n",
    "- **Precisión:** Alta tendencia al sobreajuste (memorizar datos)\n",
    "- **Velocidad:** Rápido. La validación de reglas son condicionales\n",
    "- **Explicativo:** Sí\n",
    "- **Sensible a cambios:** Si, pequeños cambios en los datos puede resultar en árboles completamente diferentes.\n",
    "- **Deteminístico**: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree= DecisionTreeClassifier(max_depth=3)\n",
    "model_tree.fit(x_train, y_train)\n",
    "print('Error: {}'.format(1 - model_tree.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada uno de los nodos, el algoritmo valida qué variable y qué valor de esa variable produce un nivel mayor de \"pureza\" entre las hojas (*Entropía/gini index*).  Si este nivel no es suficiente para dar una buena decisión, se hace una nueva partición en cada una de las hojas, validando nuevamente todas las variables predictivas.  \n",
    "Por esto mismo, los árboles de decisión tienen varios parámetros que configurar (Nivel mínimo de entropía, profundidad máxima del árbol, mínima cantidad de muestras para las hojas, etc.)  \n",
    "Otra de las ventajas de los árboles es que son **tan explicativos**, que pueden ser graficados para validar el proceso de toma de cada decisión en el proceso de predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(model_tree, \n",
    "               feature_names=x.columns,  \n",
    "               class_names=['BAJA', 'ALTA'],\n",
    "               filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las columas a incluir en el modelo, así como con los parámetros de la función *DecisionTreeClassifier()*, como por ejemplo: *max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes, ...*\n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_tree.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_tree, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensambles de Modelos\n",
    "Cuando un modelo es **no determinístico**, pero tiende al **sobreajuste**, es decir, aprende de memoria las reglas y patrones del set de entrenamiento, hasta el punto de no predecir correctamente sobre el test de entrenamiento, esto puede solucionarse haciendo un ensamble o conjunto de modelos.  Esto es, construir varios modelos \"débiles\" y crear uno \"robusto\", tomando la decisión final dependiendo de:\n",
    "- \"Democracia\", el resultado es lo que diga la mayoría de modelos, realizando cada uno **bajo un set de entrenamiento diferente** (*BaggingClassifier*)\n",
    "- \"Aleatorio\", el resultado es lo que diga la mayoría de árboles de decisión, realizando cada uno con un set aleatorio de  variables (*RandomForestClassifier*)\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/3-s2.0-B9780128177365000090-f09-17-9780128177365.jpg\" alt=\"Rnd Forest\" width=\"500\"/>\n",
    "\n",
    "- **Precisión:** Alta, varios modelos eliminan el sobreajuste\n",
    "- **Velocidad:** Lento, por velocidad se sacrifica precisión\n",
    "- **Explicativo:** Sí, aunque no entrega el modelo, entre importancia de variables\n",
    "- **Sensible a cambios:** No mucho, un dato atípico peude modificar un árbol, pero no todos\n",
    "- **Deteminístico**: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest= RandomForestClassifier(n_estimators=20, max_depth=5)\n",
    "model_forest.fit(x_train, y_train)\n",
    "print('Error: {}'.format(1 - model_forest.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que, si la anterior celda se ejecuta varias veces, cada vez da un valor diferente.  Esto significa que el modelo es **no determinístico**.  Aunque el error cambie con solo ejecutarlo, es mejor configurar algunos parámetros para indicarle al modelo por dónde está la mejor solución.  \n",
    "El concenso realizado entre los modelos permite al algoritmo, a pesar de ser no determinístico, darse una idea de la importancia de cada variable en la toma de la decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, imp in zip(x.columns, model_forest.feature_importances_) :\n",
    "    print('{}: {:.2f}'.format(col, imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taller**  \n",
    "Juegue un poco con las columnas a incluir en el modelo, en este caso revise la importancia de variables.  \n",
    "Puede también jugar con los parámetros de la función *RandomForestClassifier()*, que son los mismos del Árbol de Decisión con la adición de *n_estimators* (Cantidad de modelos/árboles a generar)\n",
    "\n",
    "Una vez encuentre un modelo que considere adecuado, vamos a a guardarlo para futuros laboratorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/model_forest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_forest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
